{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNL prediction demo\n",
    "\n",
    "Sam Maurer, August 2017 | Python 3.6\n",
    "\n",
    "Original version July 2017  \n",
    "Updated July 2017 to include probabilities  \n",
    "Updated Aug 2017 to fix int/float problems \n",
    "\n",
    "### Summary\n",
    "\n",
    "This notebook demonstrates how to fit a model using the ChoiceModels interface and then use the UrbanSim MNL functions to generate probabilities and predictions. \n",
    "\n",
    "Eventually, a prediction interface will be incorporated into the `MultinomialLogitResults` object, but it's not there yet!\n",
    "\n",
    "This demo uses the estimation data that's set up in the `Data-prep-02` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maurer/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from patsy import dmatrix\n",
    "\n",
    "from choicemodels import mnl  # could also import form urbansim.urbanchoice\n",
    "from choicemodels import MultinomialLogit\n",
    "from choicemodels.tools import MergedChoiceTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1566\n",
      "                   city  home_density  work_density  school_density\n",
      "full_tract_id                                                      \n",
      "6001400100     BERKELEY     13.437961     13.130867       13.511570\n",
      "6001400200      OAKLAND     11.089638      4.248928        0.894794\n",
      "6001400300      OAKLAND     28.878399      7.671554        0.000000\n"
     ]
    }
   ],
   "source": [
    "tracts = pd.read_csv('../data/tracts_v02.csv').set_index('full_tract_id')\n",
    "tracts = tracts.loc[(tracts.home_density > 0) | (tracts.work_density > 0) | (tracts.school_density > 0)]\n",
    "\n",
    "print(tracts.shape[0])\n",
    "print(tracts.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35786\n",
      "             full_tract_id  mode  trip_distance_miles\n",
      "place_id                                             \n",
      "10319850202     6095251902     5             5.125960\n",
      "10335860102     6085511915     6           156.370628\n",
      "10335860103     6085512027     6             1.615535\n"
     ]
    }
   ],
   "source": [
    "trips = pd.read_csv('../data/trips_v02.csv').set_index('place_id')\n",
    "trips = trips.loc[trips.trip_distance_miles.notnull()]\n",
    "\n",
    "print(trips.shape[0])\n",
    "print(trips.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up estimation table\n",
    "\n",
    "Each observed trip is a realized choice of a particular destination census tract. We can randomly sample alternative census tracts to build a model of destination choice.\n",
    "\n",
    "We'll divide the trips into a training set and a testing set, fit an MNL model using the training data, use it to generate predicted choices for the testing data, and compare the predicted to the actual choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maurer/Dropbox/Git-imac/udst/choicemodels/choicemodels/tools/interaction.py:221: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  alts_sample['join_index'] = np.repeat(choosers.index.values, SAMPLE_SIZE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 9)\n",
      "(3473300, 9)\n"
     ]
    }
   ],
   "source": [
    "training_observations = trips.iloc[:1000]\n",
    "training = MergedChoiceTable(observations = training_observations,\n",
    "                             alternatives = tracts,\n",
    "                             chosen_alternatives = training_observations.full_tract_id,\n",
    "                             sample_size = 100)\n",
    "\n",
    "testing_observations = trips.iloc[1000:]\n",
    "testing = MergedChoiceTable(observations = testing_observations,\n",
    "                            alternatives = tracts,\n",
    "                            chosen_alternatives = testing_observations.full_tract_id,\n",
    "                            sample_size = 100)\n",
    "\n",
    "print(training.to_frame().shape)\n",
    "print(testing.to_frame().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a model using the training observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  CHOICEMODELS ESTIMATION RESULTS                  \n",
      "===================================================================\n",
      "Dep. Var.:                chosen   No. Observations:               \n",
      "Model:         Multinomial Logit   Df Residuals:                   \n",
      "Method:       Maximum Likelihood   Df Model:                       \n",
      "Date:                              Pseudo R-squ.:                  \n",
      "Time:                              Pseudo R-bar-squ.:              \n",
      "AIC:                               Log-Likelihood:       -4,498.317\n",
      "BIC:                               LL-Null:              -4,605.170\n",
      "===================================================================\n",
      "                    coef   std err         z     P>|z|   Conf. Int.\n",
      "-------------------------------------------------------------------\n",
      "home_density      0.0120     0.002     6.393                       \n",
      "work_density      0.0129     0.001    15.988                       \n",
      "school_density    0.0078     0.004     2.144                       \n",
      "===================================================================\n",
      "CPU times: user 362 ms, sys: 82.8 ms, total: 445 ms\n",
      "Wall time: 187 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maurer/Dropbox/Git-imac/udst/choicemodels/choicemodels/tools/pmat.py:48: RuntimeWarning: overflow encountered in exp\n",
      "  return PMAT(np.exp(self.mat))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_expression = \"home_density + work_density + school_density - 1\"\n",
    "\n",
    "model = MultinomialLogit(data = training.to_frame(), \n",
    "                         observation_id_col = training.observation_id_col, \n",
    "                         choice_col = training.choice_col,\n",
    "                         model_expression = model_expression)\n",
    "\n",
    "results = model.fit()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict destination choices for the testing observations\n",
    "\n",
    "We'll use the UrbanSim MNL functions directly, because this hasn't been integrated into the ChoiceModels results classes yet. https://github.com/UDST/choicemodels/blob/master/choicemodels/mnl.py#L536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.011960\n",
      "1    0.012945\n",
      "2    0.007753\n",
      "Name: Coefficient, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Pull the coefs out of the results object (the PyLogit syntax would be different)\n",
    "\n",
    "coefs = results.get_raw_results()['fit_parameters']['Coefficient']\n",
    "print(coefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3473300, 3)\n",
      "               home_density  work_density  school_density\n",
      "full_tract_id                                            \n",
      "6097150607        10.659461      6.868701        7.160030\n",
      "6097151502        18.674865      1.820991        1.856286\n",
      "6081609700        27.867920      0.000000        0.000000\n"
     ]
    }
   ],
   "source": [
    "# The data columns for prediction need to align with the coefficients; \n",
    "# you can do this manually or with patsy, as here\n",
    "\n",
    "df = testing.to_frame().set_index('full_tract_id')\n",
    "\n",
    "testing_df = dmatrix(model_expression, data=df, return_type='dataframe')\n",
    "print(testing_df.shape)\n",
    "print(testing_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34733\n",
      "[93 39 89 56 67]\n"
     ]
    }
   ],
   "source": [
    "# Simulate a destination choice for each testing observation\n",
    "\n",
    "choices = mnl.mnl_simulate(testing_df, coefs, numalts=100, returnprobs=False)\n",
    "\n",
    "print(len(choices))\n",
    "print(choices[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'd']\n"
     ]
    }
   ],
   "source": [
    "# Annoyingly, that identifies the choices by position rather than by id;\n",
    "# here's a function to get the id's\n",
    "\n",
    "def get_chosen_ids(ids, positions):\n",
    "    \"\"\"\n",
    "    We observe N choice scenarios. In each, one of J alternatives is chosen.\n",
    "    We have a long (len N * J) list of the available alternatives. We have a \n",
    "    list (len N) of which alternatives were chosen, but it identifies them \n",
    "    by POSITION and we want their ID.    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ids : list or list-like\n",
    "        List of alternative ID's (len N * J).\n",
    "        \n",
    "    positions : list or list-like\n",
    "        List of chosen alternatives by position (len N), where each entry is\n",
    "        an int in range [0, J)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    chosen_ids : list\n",
    "        List of chosen alternatives by ID (len N)\n",
    "    \n",
    "    \"\"\"\n",
    "    N = len(positions)\n",
    "    J = len(ids) // N\n",
    "    \n",
    "    ids_by_obs = np.reshape(ids, (N,J))\n",
    "    return [ids_by_obs[i][positions[i]] for i in range(N)]\n",
    "    \n",
    "\n",
    "print(get_chosen_ids(['a','b','c','d'], [0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34733\n",
      "[6001400900, 6075045100, 6013355301, 6001406202, 6085504410]\n"
     ]
    }
   ],
   "source": [
    "# Get tract id's for the simulated choices\n",
    "\n",
    "predicted_tracts = get_chosen_ids(testing_df.index.tolist(), choices)\n",
    "\n",
    "print(len(predicted_tracts))\n",
    "print(predicted_tracts[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34733\n",
      "[6097150607, 6097153200, 6097151402, 6097151402, 6097151204]\n"
     ]
    }
   ],
   "source": [
    "# Get tract id's for observed choices\n",
    "\n",
    "df = testing.to_frame()\n",
    "observed_tracts = df.loc[df.chosen == 1, 'full_tract_id'].tolist()\n",
    "\n",
    "print(len(observed_tracts))\n",
    "print(observed_tracts[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the predicted choices to the observed ones\n",
    "\n",
    "Multinomial models are kind of tricky to validate. We don't expect the actual choices to match, because there are so many alternatives, but we do expect the characteristics of the predicted choices to be similar to the characteristics of the observed choices. \n",
    "\n",
    "Choose your own metric for this depending on what you're trying to evaluate! It's even plausible that the metric could be something not directly in the model, like the distance between the predicted and actual destination choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0156047562836\n"
     ]
    }
   ],
   "source": [
    "# What portion of predicted destination choices were a perfect match?\n",
    "# With an uninformative model we would expect 0.01, given that the \n",
    "# observed choice is included in the 100 available alternatives.\n",
    "\n",
    "perfect_match = np.equal(predicted_tracts, observed_tracts)\n",
    "print(sum(perfect_match)/len(perfect_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.138159532444\n"
     ]
    }
   ],
   "source": [
    "# What's the correlation between employment density of the predicted and \n",
    "# observed destinations? With an uninformative model we would expect 0.\n",
    "\n",
    "density_1 = pd.Series([tracts.loc[t,'work_density'] for t in predicted_tracts])\n",
    "density_2 = pd.Series([tracts.loc[t,'work_density'] for t in observed_tracts])\n",
    "\n",
    "print(density_1.corr(density_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does UrbanSim generate household location choices?\n",
    "\n",
    "These three class methods collectively set up the choosers and alternatives according to various parameters like the sample size, prediction filters, \"probability mode,\" and \"choice mode\" (aggregate or individual):\n",
    "\n",
    "- `urbansim.models.MNLDiscreteChocieModel.probabilities()` \n",
    "- `urbansim.models.MNLDiscreteChocieModel.summed_probabilities()` \n",
    "- `urbansim.models.MNLDiscreteChocieModel.predict()` \n",
    "\n",
    "https://github.com/UDST/urbansim/blob/master/urbansim/models/dcm.py#L474\n",
    "\n",
    "Then this lower-level function generates a table of probabilities for each alternative, which is passed back to the `MNLDiscreteChoiceModel` class for further processing:\n",
    "\n",
    "- `urbansim.urbanchoice.mnl.mnl_simulate()`\n",
    "\n",
    "https://github.com/UDST/urbansim/blob/master/urbansim/urbanchoice/mnl.py#L121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Generate probabilities instead of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.011960\n",
      "1    0.012945\n",
      "2    0.007753\n",
      "Name: Coefficient, dtype: float64\n",
      "(3473300, 3)\n",
      "               home_density  work_density  school_density\n",
      "full_tract_id                                            \n",
      "6097150607        10.659461      6.868701        7.160030\n",
      "6097151502        18.674865      1.820991        1.856286\n",
      "6081609700        27.867920      0.000000        0.000000\n"
     ]
    }
   ],
   "source": [
    "# Use coefs and testing dataset from above\n",
    "\n",
    "print(coefs)\n",
    "print(testing_df.shape)\n",
    "print(testing_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34733, 100)\n",
      "[[ 0.01027528  0.01016694  0.01092577  0.00952525  0.01036695]\n",
      " [ 0.01043302  0.0137536   0.00928926  0.00886562  0.01099936]\n",
      " [ 0.01185824  0.00912012  0.00813987  0.0082176   0.00935786]\n",
      " [ 0.01152868  0.00832404  0.00775938  0.00822781  0.00909811]\n",
      " [ 0.00644534  0.00714275  0.00711916  0.00645062  0.0082218 ]]\n"
     ]
    }
   ],
   "source": [
    "probs = mnl.mnl_simulate(testing_df, coefs, numalts=100, returnprobs=True)\n",
    "\n",
    "print(probs.shape)\n",
    "print(probs[:5,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chooser_id   alternative_id\n",
      "11485050104  6097150607        0.010275\n",
      "             6097151502        0.010167\n",
      "             6081609700        0.010926\n",
      "             6001431000        0.009525\n",
      "             6095252704        0.010367\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Join probabilities to a multi-index of chooser and alternative id's\n",
    "# Code adapted from UrbanSim: \n",
    "#   https://github.com/UDST/urbansim/blob/master/urbansim/models/dcm.py#L549-L556\n",
    "\n",
    "mi = pd.MultiIndex.from_arrays(\n",
    "        [testing.to_frame()[testing.observation_id_col], \n",
    "         testing.to_frame()[testing.alternative_id_col]],\n",
    "        names=('chooser_id', 'alternative_id'))\n",
    "\n",
    "probs_df = pd.Series(probs.flatten(), index=mi)\n",
    "\n",
    "print(probs_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum the probabilities\n",
    "\n",
    "Calculate the total probability associated with each alternative. This approach is adapted from UrbanSim. \n",
    "\n",
    "https://github.com/UDST/urbansim/blob/master/urbansim/models/dcm.py#L562-L597\n",
    "\n",
    "Conceptually, the fitted model implies a probability density function (PDF) for each agent choosing among a set of alternatives. Here we're summing the densities across agents to get a single density function that can serve as a proxy for the aggregate appeal of the alternatives.\n",
    "\n",
    "Important note! What we're actually creating here (I think) is PDFs over the alternatives sampled for each chooser. With random sampling, the sum will approximate a PDF over all the alternatives. Non-random sampling will alter the interpretation -- it's still a measure of aggregate appeal, but conditioned on the sampling procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alternative_id\n",
      "6001400100    0.259805\n",
      "6001400200    0.268773\n",
      "6001400300    0.210791\n",
      "6001400400    0.312045\n",
      "6001400500    0.414284\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Code adapted from UrbanSim - For each chooser, normalize the probabilities so\n",
    "# they sum to 1 (is this really necessary?). Then sum the probabilties associated\n",
    "# with each alternative. I'm using the first 500 choosers for efficiency.\n",
    "\n",
    "def normalize(s):\n",
    "    return s / s.sum()\n",
    "\n",
    "summed_probs = probs_df[:50000].groupby(level=0).apply(normalize).groupby(level=1).sum()\n",
    "\n",
    "print(summed_probs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
