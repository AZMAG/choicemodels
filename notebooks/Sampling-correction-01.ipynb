{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling correction for large choice sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sam Maurer, Nov. 21, 2016 (updated Dec. 6 to remove errors)\n",
    "\n",
    "1. Replicate synthetic data from Guevara & Ben-Akiva 2013\n",
    "2. Do MNL with and without sampling correction\n",
    "3. Check whether parameter estimates deviate from true values\n",
    "4. Extend to Mixed Logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Generate synthetic data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- N = 1000 observations\n",
    "- J = 1000 alternatives for all observations (C_n = C)\n",
    "- X = single attribute distributed Uniform(-2,1) for the first 500 alternatives and Uniform(-1,2) for the second half\n",
    "- beta = generic linear taste coefficient, distributed Normal(mu=1.5, sigma=0.8) across the 1000 observations\n",
    "- systematic utility = beta * X\n",
    "- epsilon = error term distributed ExtremeValue(0,1)\n",
    "- random utility = beta * X + epsilon\n",
    "\n",
    "Utility of alternative i for agent n:\n",
    "$$ U_{in} = V_{in} + \\varepsilon_{in} = \\beta_n x_{i} + \\varepsilon_{in} $$\n",
    "\n",
    "Probability that agent n will choose alternative i:\n",
    "$$ L_n(i \\mid \\beta_n, x_n,C_n) = \\frac {e^{V_{in}}} {\\sum_{j \\epsilon C_n} e^{V_{jn}}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "[-1.53751147  0.22014909 -1.21005495 -0.39878182 -1.95627511]\n"
     ]
    }
   ],
   "source": [
    "# Generate attribute x for each of J alternatives\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(12)\n",
    "\n",
    "# Start with J << 1000 to speed up runtimes\n",
    "\n",
    "J = 50  # alternatives\n",
    "\n",
    "Xa = 3 * np.random.rand(J/2) - 2  # uniform distribution over [-2, 1]\n",
    "Xb = 3 * np.random.rand(J/2) - 1  # uniform distribution over [-1, 2]\n",
    "\n",
    "X = np.concatenate((Xa, Xb))\n",
    "\n",
    "print len(X)\n",
    "print X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[ 1.5  1.5  1.5  1.5  1.5]\n"
     ]
    }
   ],
   "source": [
    "# Generate taste coefficient beta for each of N agents \n",
    "\n",
    "# For regular MNL, i think we need to use a single value, instead of a \n",
    "# distribution as Guevara & Ben-Akiva used for the mixture model\n",
    "\n",
    "N = 1000  # agents/observations\n",
    "\n",
    "beta = np.zeros(1000) + 1.5\n",
    "# beta = 0.8 * np.random.randn(N) + 1.5\n",
    "\n",
    "print len(beta)\n",
    "print beta[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print pd.DataFrame(beta).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 50)\n"
     ]
    }
   ],
   "source": [
    "# Generate probability matrix for N agents choosing among J alternatives\n",
    "\n",
    "def probs(n):\n",
    "    ''' \n",
    "    Return list of J probabilities for agent n\n",
    "    '''\n",
    "    b = beta[n]\n",
    "    exps = [np.exp(b*x) for x in X]\n",
    "    sum_exps = np.sum(exps)\n",
    "    return [exp/sum_exps for exp in exps]\n",
    "\n",
    "P = np.array([probs(n) for n in range(N)])\n",
    "    \n",
    "print P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Check that each row sums to 1\n",
    "\n",
    "print np.sum(P, axis=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[12, 41, 37, 5, 30, 27, 8, 35, 33, 6]\n"
     ]
    }
   ],
   "source": [
    "# Simulate a choice from J alternatives for each of N agents\n",
    "\n",
    "C = [np.random.choice(range(J), p=p) for p in P]\n",
    "\n",
    "print len(C)\n",
    "print C[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Now we have data:\n",
    "\n",
    "- N agents/observations with true taste coefficients in array \"beta\"\n",
    "- J alternatives with single attributes in array \"X\"\n",
    "- N choice outcomes in array \"C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Estimate beta without sampling, using PyLogit MNL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pylogit\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "# Set up an estimation dataset in long format\n",
    "\n",
    "d = [[n, i, int(C[n]==i), X[i]] for n in range(N) for i in range(J)]\n",
    "\n",
    "print len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   obs_id  alt_id  choice         x\n",
      "0       0       0       0 -1.537511\n",
      "1       0       1       0  0.220149\n",
      "2       0       2       0 -1.210055\n",
      "3       0       3       0 -0.398782\n",
      "4       0       4       0 -1.956275 \n",
      "\n",
      "             obs_id        alt_id        choice             x\n",
      "count  50000.000000  50000.000000  50000.000000  50000.000000\n",
      "mean     499.500000     24.500000      0.020000      0.014570\n",
      "std      288.677877     14.431014      0.140001      1.116965\n",
      "min        0.000000      0.000000      0.000000     -1.993222\n",
      "25%      249.750000     12.000000      0.000000     -0.894495\n",
      "50%      499.500000     24.500000      0.000000      0.220035\n",
      "75%      749.250000     37.000000      0.000000      0.832675\n",
      "max      999.000000     49.000000      1.000000      1.985414\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(d, columns=['obs_id', 'alt_id', 'choice', 'x'])\n",
    "\n",
    "print df.head(), '\\n'\n",
    "print df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up model spec\n",
    "\n",
    "spec = OrderedDict([\n",
    "        ('x', [range(J)])\n",
    "    ])\n",
    "\n",
    "labels = OrderedDict([\n",
    "        ('x', ['beta_x'])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at zero: -3,912.0230\n",
      "Initial Log-likelihood: -3,912.0230\n",
      "Estimation Time: 0.07 seconds.\n",
      "Final log-likelihood: -3,065.1983\n",
      "                     Multinomial Logit Model Regression Results                    \n",
      "===================================================================================\n",
      "Dep. Variable:                      choice   No. Observations:                1,000\n",
      "Model:             Multinomial Logit Model   Df Residuals:                      999\n",
      "Method:                                MLE   Df Model:                            1\n",
      "Date:                     Mon, 21 Nov 2016   Pseudo R-squ.:                   0.216\n",
      "Time:                             13:52:41   Pseudo R-bar-squ.:               0.216\n",
      "converged:                            True   Log-Likelihood:             -3,065.198\n",
      "                                             LL-Null:                    -3,912.023\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "beta_x         1.5324      0.046     33.649      0.000         1.443     1.622\n",
      "==============================================================================\n",
      "CPU times: user 7.7 s, sys: 14.1 s, total: 21.8 s\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m = pylogit.create_choice_model(data = df, \n",
    "                                alt_id_col = 'alt_id', \n",
    "                                obs_id_col = 'obs_id', \n",
    "                                choice_col = 'choice', \n",
    "                                specification = spec, \n",
    "                                model_type = \"MNL\", \n",
    "                                names = labels)\n",
    "\n",
    "m.fit_mle(init_vals = np.array([0]))\n",
    "print m.get_statsmodels_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Try with UrbanSim MNL instead of PyLogit\n",
    "\n",
    "Model class: https://github.com/UDST/urbansim/blob/master/urbansim/models/dcm.py\n",
    "\n",
    "Estimation algorithms: https://github.com/UDST/urbansim/blob/master/urbansim/urbanchoice/mnl.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urbansim.models import MNLDiscreteChoiceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# Choosers should be a DataFrame of characteristics, with index as identifier\n",
    "\n",
    "d = [[n, C[n]] for n in range(N)]\n",
    "\n",
    "choosers = pd.DataFrame(d, columns=['id', 'choice']).set_index('id')\n",
    "\n",
    "print len(choosers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# Alternatives should be a DataFrame of characteristics, with index as identifier\n",
    "\n",
    "d = [[i, X[i]] for i in range(J)]\n",
    "\n",
    "alts = pd.DataFrame(d, columns=['id', 'x']).set_index('id')\n",
    "\n",
    "print len(alts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Log-liklihood: -3891.820\n",
      "Log-liklihood at convergence: -3077.869\n",
      "Log-liklihood Ratio: 0.209\n",
      "\n",
      "+-----------+-------------+------------+---------+\n",
      "| Component | Coefficient | Std. Error | T-Score |\n",
      "+-----------+-------------+------------+---------+\n",
      "| x         |    1.527    |   0.022    |  69.267 |\n",
      "+-----------+-------------+------------+---------+\n",
      "CPU times: user 104 ms, sys: 9.03 ms, total: 113 ms\n",
      "Wall time: 89.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# It seems like this implementation *requires* us to sample the alternatives, \n",
    "# so here i'm estimating the model with J-1 alts\n",
    "\n",
    "m = MNLDiscreteChoiceModel(model_expression = 'x',\n",
    "                           sample_size = J-1)\n",
    "\n",
    "m.fit(choosers = choosers,\n",
    "      alternatives = alts,\n",
    "      current_choice = 'choice')\n",
    "\n",
    "m.report_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. MNL, sampling alternatives without correction\n",
    "\n",
    "(NB - with random sampling, no correction is needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the estimation dataset, for each observation include a row for the\n",
    "# chosen alternative, plus K-1 other alternatives sampled randomly\n",
    "# without replacement, where K < J."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 23, 7]\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "\n",
    "def alts(obs_id):\n",
    "    \"\"\"\n",
    "    Sample alternatives for observation `obs_id`. Expects `J` total\n",
    "    alts, `K` sampled alts, list `C` of choice outcomes. Returns list \n",
    "    of K alt id's including the chosen one.\n",
    "    \"\"\"\n",
    "    chosen = C[obs_id]  # id of chosen alternative\n",
    "    unchosen = [i for i in range(J) if chosen != i]  # id's of J-1 unchosen alts\n",
    "    sample_unchosen = np.random.choice(unchosen, size=K-1, replace=False)\n",
    "    return [chosen] + sample_unchosen.tolist()\n",
    "    \n",
    "print alts(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "# Set up the estimation dataset\n",
    "\n",
    "d = [[n, i, int(C[n]==i), X[i]] for n in range(N) for i in alts(n)]\n",
    "\n",
    "print len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   obs_id  alt_id  choice         x\n",
      "0       0      12       1  0.832675\n",
      "1       0       3       0 -0.398782\n",
      "2       0      35       0  1.850941\n",
      "3       1      41       1  1.985414\n",
      "4       1      45       0  0.272157 \n",
      "\n",
      "            obs_id       alt_id       choice            x\n",
      "count  3000.000000  3000.000000  3000.000000  3000.000000\n",
      "mean    499.500000    26.898000     0.333333     0.446787\n",
      "std     288.723115    13.974669     0.471483     1.170677\n",
      "min       0.000000     0.000000     0.000000    -1.993222\n",
      "25%     249.750000    14.000000     0.000000    -0.181750\n",
      "50%     499.500000    29.000000     0.000000     0.413689\n",
      "75%     749.250000    38.000000     1.000000     1.448505\n",
      "max     999.000000    49.000000     1.000000     1.985414\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(d, columns=['obs_id', 'alt_id', 'choice', 'x'])\n",
    "\n",
    "print df.head(), '\\n'\n",
    "print df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Same model spec as before\n",
    "\n",
    "spec = OrderedDict([\n",
    "        ('x', [range(J)])\n",
    "    ])\n",
    "\n",
    "labels = OrderedDict([\n",
    "        ('x', ['beta_x'])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at zero: -1,098.6123\n",
      "Initial Log-likelihood: -1,098.6123\n",
      "Estimation Time: 0.02 seconds.\n",
      "Final log-likelihood: -585.7551\n",
      "                     Multinomial Logit Model Regression Results                    \n",
      "===================================================================================\n",
      "Dep. Variable:                      choice   No. Observations:                1,000\n",
      "Model:             Multinomial Logit Model   Df Residuals:                      999\n",
      "Method:                                MLE   Df Model:                            1\n",
      "Date:                     Sun, 20 Nov 2016   Pseudo R-squ.:                   0.467\n",
      "Time:                             14:37:24   Pseudo R-bar-squ.:               0.466\n",
      "converged:                            True   Log-Likelihood:               -585.755\n",
      "                                             LL-Null:                    -1,098.612\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "beta_x         1.6151      0.077     20.888      0.000         1.464     1.767\n",
      "==============================================================================\n",
      "CPU times: user 303 ms, sys: 41.3 ms, total: 344 ms\n",
      "Wall time: 226 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m = pylogit.create_choice_model(data = df, \n",
    "                                alt_id_col = 'alt_id', \n",
    "                                obs_id_col = 'obs_id', \n",
    "                                choice_col = 'choice', \n",
    "                                specification = spec, \n",
    "                                model_type = \"MNL\", \n",
    "                                names = labels)\n",
    "\n",
    "m.fit_mle(init_vals = np.array([0]))\n",
    "print m.get_statsmodels_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 1000x with different samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def estimate_beta():\n",
    "    d = [[n, i, int(C[n]==i), X[i]] for n in range(N) for i in alts(n)]\n",
    "    df = pd.DataFrame(d, columns=['obs_id', 'alt_id', 'choice', 'x'])\n",
    "    m = pylogit.create_choice_model(df, 'alt_id', 'obs_id', 'choice', spec, 'MNL', names=labels)\n",
    "    m.fit_mle(init_vals = np.array([0]))\n",
    "    return m.params.beta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "beta = []\n",
    "for i in range(1000):\n",
    "    beta.append(estimate_beta())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1000.000000\n",
      "mean        1.508913\n",
      "std         0.052854\n",
      "min         1.322523\n",
      "25%         1.471155\n",
      "50%         1.507724\n",
      "75%         1.545232\n",
      "max         1.674443\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print pd.Series(beta).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MNL with sampling correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility of alternative j:\n",
    "$$ V_{j} = \\beta x_{j} $$\n",
    "\n",
    "With sampling, we have to account for the restricted choice set (from Eq 6 in Guevara & Ben-Akiva 2013):\n",
    "\n",
    "$$ V_j = \\beta x_j + \\ln \\pi(D \\mid j) $$\n",
    "\n",
    "Where pi is the conditional probability that we would construct the choice set D given that alternative j was chosen. This goes into the likelihood function in both the numerator and denominator.\n",
    "\n",
    "$$ L_n = \\frac {exp(\\beta x_i + \\ln \\pi(D_n \\mid i))} {\\sum_{j \\epsilon D_n} exp(\\beta x_j + \\ln \\pi(D_n \\mid j))} $$\n",
    "\n",
    "How to calculate pi? From the original formulation of this in McFadden 1978: \"Suppose D is comprized of i plus a sample of alternatives from the set C\\\\{i}, obtained by considering each element of this set independently, and including it with probability p. Then, the probability of D will depend solely on the number of elements K it contains.\"\n",
    "\n",
    "$$ \\pi(D) = p^{K-1} (1 - p)^{J-K} $$\n",
    "\n",
    "(?? Without replacement, i think it should be the n-choose-k binomial coefficient, where n=J-1 and k=K-1)\n",
    "\n",
    "$$ \\pi(D) = {n \\choose k} = \\frac {(K-1)!(J-K)!} {(J-1)!} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   obs_id  alt_id  choice         x  const\n",
      "0       0      12       1  0.832675      1\n",
      "1       0      24       0 -1.070307      1\n",
      "2       0       4       0 -1.956275      1\n",
      "3       1      41       1  1.985414      1\n",
      "4       1      26       0  0.413689      1 \n",
      "\n",
      "            obs_id       alt_id       choice            x   const\n",
      "count  3000.000000  3000.000000  3000.000000  3000.000000  3000.0\n",
      "mean    499.500000    26.777667     0.333333     0.438763     1.0\n",
      "std     288.723115    13.883149     0.471483     1.180510     0.0\n",
      "min       0.000000     0.000000     0.000000    -1.993222     1.0\n",
      "25%     249.750000    15.000000     0.000000    -0.343887     1.0\n",
      "50%     499.500000    29.000000     0.000000     0.413689     1.0\n",
      "75%     749.250000    38.000000     1.000000     1.448505     1.0\n",
      "max     999.000000    49.000000     1.000000     1.985414     1.0\n"
     ]
    }
   ],
   "source": [
    "# Add a column in the estimation data for the constant\n",
    "\n",
    "d = [[n, i, int(C[n]==i), X[i], 1] for n in range(N) for i in alts(n)]\n",
    "\n",
    "df = pd.DataFrame(d, columns=['obs_id', 'alt_id', 'choice', 'x', 'const'])\n",
    "\n",
    "print df.head(), '\\n'\n",
    "print df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spec2 = OrderedDict([\n",
    "        ('x', [range(J)]),\n",
    "        ('const', [range(J)])\n",
    "    ])\n",
    "\n",
    "labels2 = OrderedDict([\n",
    "        ('x', ['beta_x']),\n",
    "        ('const', ['constant'])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try binomial formula\n",
    "\n",
    "j=3\n",
    "k=2\n",
    "\n",
    "fact = np.math.factorial\n",
    "\n",
    "float(fact(k-1)*fact(j-k))/fact(j-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at zero: -1,098.6123\n",
      "Initial Log-likelihood: -1,098.6123\n",
      "Estimation Time: 0.02 seconds.\n",
      "Final log-likelihood: -613.3560\n",
      "                     Multinomial Logit Model Regression Results                    \n",
      "===================================================================================\n",
      "Dep. Variable:                      choice   No. Observations:                1,000\n",
      "Model:             Multinomial Logit Model   Df Residuals:                      998\n",
      "Method:                                MLE   Df Model:                            2\n",
      "Date:                     Mon, 21 Nov 2016   Pseudo R-squ.:                   0.442\n",
      "Time:                             13:47:43   Pseudo R-bar-squ.:               0.440\n",
      "converged:                            True   Log-Likelihood:               -613.356\n",
      "                                             LL-Null:                    -1,098.612\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "beta_x         1.5376      0.075     20.586      0.000         1.391     1.684\n",
      "constant      -7.0699   1.31e+07  -5.39e-07      1.000     -2.57e+07  2.57e+07\n",
      "==============================================================================\n",
      "CPU times: user 325 ms, sys: 29.7 ms, total: 355 ms\n",
      "Wall time: 237 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m = pylogit.create_choice_model(data = df, \n",
    "                                alt_id_col = 'alt_id', \n",
    "                                obs_id_col = 'obs_id', \n",
    "                                choice_col = 'choice', \n",
    "                                specification = spec2, \n",
    "                                model_type = \"MNL\", \n",
    "                                names = labels2)\n",
    "\n",
    "# p = float(K-1)/(J-1)\n",
    "# const = np.log(p**(K-1) * (1-p)**(J-K))\n",
    "\n",
    "const = np.log(float(fact(K-1)*fact(J-K))/fact(J-1))\n",
    "\n",
    "# Add an initial value for the constant and constrain it to that\n",
    "m.fit_mle(init_vals = np.array([0, const]), \n",
    "          constrained_pos=[1])\n",
    "\n",
    "print m.get_statsmodels_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 1000x with different samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try binomial formula\n",
    "const = np.log(float(fact(K-1)*fact(J-K))/fact(J-1))\n",
    "\n",
    "def estimate_beta_with_correction():\n",
    "    d = [[n, i, int(C[n]==i), X[i], 1] for n in range(N) for i in alts(n)]\n",
    "    df = pd.DataFrame(d, columns=['obs_id', 'alt_id', 'choice', 'x', 'const'])\n",
    "    m = pylogit.create_choice_model(df, 'alt_id', 'obs_id', 'choice', spec2, 'MNL', names=labels2)\n",
    "    m.fit_mle(init_vals = np.array([0, const]), constrained_pos=[1])\n",
    "    return m.params.beta_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "beta = []\n",
    "for i in range(1000):\n",
    "    beta.append(estimate_beta_with_correction())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1000.000000\n",
      "mean        1.513490\n",
      "std         0.051725\n",
      "min         1.354507\n",
      "25%         1.477341\n",
      "50%         1.512756\n",
      "75%         1.548081\n",
      "max         1.736557\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print pd.Series(beta).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB - the correction isn't needed for the random sampling case, but we can adapt this code for stratified sampling later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
